{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3B2TYycdkmG",
        "outputId": "2ca83985-1f01-4221-a65a-0a69f2ccb99e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/cleaned_combined_dataset_with_sentiment.csv')\n",
        "titles = df['clean_title'].astype(str).tolist()\n"
      ],
      "metadata": {
        "id": "36yI3JI9dxyh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "iEpmRLojewA_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assume you already have:\n",
        "# titles = list of cleaned title strings\n",
        "# word_to_idx = your vocabulary dictionary\n",
        "\n",
        "# Step 2: Convert titles to list of indices (with unk handling)\n",
        "def text_to_indices(title, word_to_idx, unk_idx=1):\n",
        "    return [word_to_idx.get(word, unk_idx) for word in title.split()]\n",
        "\n",
        "title_indices = [text_to_indices(title, word_to_idx) for title in titles]\n",
        "\n",
        "# Step 3: Pad/truncate sequences to fixed length\n",
        "max_len = 20\n",
        "\n",
        "def pad_sequence(seq, max_len, pad_idx=0):\n",
        "    if len(seq) < max_len:\n",
        "        return seq + [pad_idx] * (max_len - len(seq))\n",
        "    else:\n",
        "        return seq[:max_len]\n",
        "\n",
        "title_padded = [pad_sequence(seq, max_len) for seq in title_indices]\n",
        "\n",
        "# Step 4: Convert to tensor\n",
        "import torch\n",
        "title_tensors = torch.tensor(title_padded, dtype=torch.long)\n",
        "\n",
        "print(title_tensors.shape)  # should be (num_samples, max_len)\n",
        "print(title_tensors.min(), title_tensors.max())  # should be within vocab range\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlpUkdBelABQ",
        "outputId": "a24870be-116f-444a-da73-aef30b0af2c4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([971806, 20])\n",
            "tensor(0) tensor(164400)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "min_freq = 1\n",
        "counter = Counter(word for title in titles for word in title.split())\n",
        "vocab = ['<pad>', '<unk>'] + [word for word, freq in counter.items() if freq >= min_freq]\n",
        "word_to_idx = {word: i for i, word in enumerate(vocab)}\n",
        "print(\"Vocab size:\", len(vocab))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIVAnrUVfFZ6",
        "outputId": "6909410b-560a-40de-bc45-7621193eee9c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size: 164401\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def text_to_indices(title, word_to_idx, unk_idx=1):\n",
        "    return [word_to_idx.get(word, unk_idx) for word in title.split()]\n",
        "\n",
        "title_indices = [text_to_indices(title, word_to_idx) for title in titles]\n"
      ],
      "metadata": {
        "id": "Fgs3C0Mvldee"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_sequence(seq, max_len=20, pad_idx=0):\n",
        "    if len(seq) < max_len:\n",
        "        return seq + [pad_idx] * (max_len - len(seq))\n",
        "    else:\n",
        "        return seq[:max_len]\n",
        "\n",
        "title_padded = [pad_sequence(seq) for seq in title_indices]\n"
      ],
      "metadata": {
        "id": "_LzkC8s1ljFy"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "title_tensors = torch.tensor(title_padded, dtype=torch.long)\n",
        "print(title_tensors.shape)\n",
        "print(title_tensors.min(), title_tensors.max())  # should be <= len(vocab)-1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RoiKsMQxloYX",
        "outputId": "57f13adf-5472-44ee-8229-7c3f2ffec9cd"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([971806, 20])\n",
            "tensor(0) tensor(164400)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "OCk1QVJUdCcz"
      },
      "outputs": [],
      "source": [
        "def load_glove(path, dim):\n",
        "    embeddings_index = {}\n",
        "    with open(path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            if len(values) != dim + 1:\n",
        "                continue  # Skip malformed lines\n",
        "            word = values[0]\n",
        "            vector = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings_index[word] = vector\n",
        "    return embeddings_index\n",
        "\n",
        "\n",
        "glove_path = '/content/drive/MyDrive/glove.840B.300d.txt'\n",
        "embedding_dim = 300\n",
        "glove = load_glove(glove_path, embedding_dim)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(word_to_idx)  # Should match your vocab size, e.g. 164401\n",
        "\n",
        "# Initialize with small random values\n",
        "embedding_matrix = np.random.uniform(-0.05, 0.05, (vocab_size, embedding_dim))\n",
        "\n",
        "# Fill embedding matrix with vectors from GloVe where available\n",
        "for word, idx in word_to_idx.items():\n",
        "    vector = glove.get(word)\n",
        "    if vector is not None:\n",
        "        embedding_matrix[idx] = vector\n",
        "\n",
        "# Convert to PyTorch tensor\n",
        "embedding_matrix = torch.tensor(embedding_matrix, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "-hvOpse9m_Nk"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class BiLSTMTextEncoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, pretrained_embeddings):\n",
        "        super(BiLSTMTextEncoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.embedding.weight.data.copy_(pretrained_embeddings)\n",
        "        self.embedding.weight.requires_grad = False  # Freeze embeddings if you want\n",
        "        self.bilstm = nn.LSTM(embedding_dim, hidden_dim, bidirectional=True, batch_first=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)            # [batch_size, seq_len, embedding_dim]\n",
        "        lstm_out, _ = self.bilstm(embedded)    # [batch_size, seq_len, hidden_dim*2]\n",
        "        pooled = torch.mean(lstm_out, dim=1)   # Average pooling over seq_len\n",
        "        return pooled                          # [batch_size, hidden_dim*2]\n"
      ],
      "metadata": {
        "id": "Y0nKeGI-oFHJ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_dim = 64  # You can change this\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = BiLSTMTextEncoder(vocab_size, embedding_dim, hidden_dim, embedding_matrix).to(device)\n",
        "\n",
        "# Move your input tensor to the device\n",
        "title_tensors = title_tensors.to(device)\n"
      ],
      "metadata": {
        "id": "gBceHx1eoOY8"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "outputs = []\n",
        "\n",
        "model.eval()  # Set model to eval mode (important for dropout, batchnorm etc.)\n",
        "with torch.no_grad():\n",
        "    for i in range(0, len(title_tensors), batch_size):\n",
        "        batch = title_tensors[i:i+batch_size]\n",
        "        output = model(batch)  # output shape: (batch_size, hidden_dim*2)\n",
        "        outputs.append(output.cpu())  # Move output back to CPU for saving later\n"
      ],
      "metadata": {
        "id": "gebKe5TpoUSv"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_outputs = torch.cat(outputs, dim=0)       # Concatenate all batches\n",
        "print(all_outputs.shape)                       # Check shape: (num_samples, hidden_dim*2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ggvl0_jlqp_d",
        "outputId": "8c2976dd-41e3-4edf-9b0c-38ec22b1f907"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([971806, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Convert to numpy\n",
        "title_embeddings = all_outputs.numpy()\n",
        "\n",
        "# Save to CSV\n",
        "df_embeddings = pd.DataFrame(title_embeddings)\n",
        "df_embeddings.to_csv('/content/drive/MyDrive/title_bilstm_embeddings.csv', index=False)\n",
        "\n",
        "print(\"Embeddings saved successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5AkWPnS3qyBj",
        "outputId": "b92dd02a-a801-4505-ba4b-f4941ecf2c35"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embeddings saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#dummy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Your BiLSTMTextEncoder definition\n",
        "class BiLSTMTextEncoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, pretrained_embeddings):\n",
        "        super(BiLSTMTextEncoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.embedding.weight.data.copy_(pretrained_embeddings)\n",
        "        self.embedding.weight.requires_grad = False\n",
        "        self.bilstm = nn.LSTM(embedding_dim, hidden_dim, bidirectional=True, batch_first=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        lstm_out, _ = self.bilstm(embedded)\n",
        "        pooled = torch.mean(lstm_out, dim=1)\n",
        "        return pooled\n",
        "\n",
        "# Parameters for dummy test\n",
        "vocab_size = 1000       # vocabulary size\n",
        "embedding_dim = 300     # embedding dimension (e.g., GloVe 300d)\n",
        "hidden_dim = 64         # hidden units in LSTM\n",
        "\n",
        "# Create a random embedding matrix (pretend pretrained embeddings)\n",
        "embedding_matrix = torch.randn(vocab_size, embedding_dim)\n",
        "\n",
        "# Instantiate model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = BiLSTMTextEncoder(vocab_size, embedding_dim, hidden_dim, embedding_matrix).to(device)\n",
        "model.eval()\n",
        "\n",
        "# Create dummy input tensor (batch_size x sequence_length)\n",
        "batch_size = 4\n",
        "seq_len = 10\n",
        "dummy_input = torch.randint(0, vocab_size, (batch_size, seq_len)).to(device)\n",
        "\n",
        "# Forward pass\n",
        "with torch.no_grad():\n",
        "    dummy_output = model(dummy_input)\n",
        "\n",
        "print(\"Dummy output shape:\", dummy_output.shape)  # Expected: (4, hidden_dim*2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDhuceEvkRaj",
        "outputId": "1d265777-595d-42cf-df84-03df3c738861"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dummy output shape: torch.Size([4, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(title_tensors.dtype)  # should be torch.int64 (LongTensor)\n",
        "print(title_tensors.min(), title_tensors.max())  # should be within vocab index range\n",
        "print(title_tensors.shape)  # (num_samples, max_seq_length)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLDhtSGGkg_f",
        "outputId": "6139bf32-e522-4a40-bb48-081c574df6c9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.int64\n",
            "tensor(0) tensor(164400)\n",
            "torch.Size([971806, 20])\n"
          ]
        }
      ]
    }
  ]
}