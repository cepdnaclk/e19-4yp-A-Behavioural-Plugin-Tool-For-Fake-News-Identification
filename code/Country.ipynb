{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Shared Code"
      ],
      "metadata": {
        "id": "RXLZ9R1jL2Dc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load main dataset and demonyms\n",
        "df = pd.read_csv('all_validate.csv')\n",
        "df_copy = df.copy()\n",
        "demonyms_df = pd.read_csv('demonyms.csv', header=None)\n",
        "demonym_map = dict(zip(demonyms_df[0].str.lower(), demonyms_df[1]))"
      ],
      "metadata": {
        "id": "sy3sutqCL3lT"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. GeoText"
      ],
      "metadata": {
        "id": "AEHfZTKWL5lO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install geotext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQGM1aejTVii",
        "outputId": "085351bd-0f43-44cc-dcda-d87b4170a57e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting geotext\n",
            "  Downloading geotext-0.4.0-py2.py3-none-any.whl.metadata (2.5 kB)\n",
            "Downloading geotext-0.4.0-py2.py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: geotext\n",
            "Successfully installed geotext-0.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## With Dymonyms"
      ],
      "metadata": {
        "id": "apWqtyQ8MAy_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from geotext import GeoText\n",
        "\n",
        "def get_country_geotext_with_demonyms(text):\n",
        "    text = str(text).lower()\n",
        "    places = GeoText(text)\n",
        "    countries = places.countries\n",
        "    if countries:\n",
        "        return countries[0]\n",
        "    for word in text.split():\n",
        "        if word in demonym_map:\n",
        "            return demonym_map[word]\n",
        "    return None\n",
        "\n",
        "df_copy['predicted_country'] = df_copy['title'].apply(get_country_geotext_with_demonyms)\n",
        "found = df_copy['predicted_country'].notna().sum()\n",
        "print(f\"GeoText + Demonyms: Found {found}/{len(df_copy)} entries\")\n",
        "df_copy.to_csv('all_validate_geotext.csv', index=False)\n",
        "print(df_copy[df_copy['predicted_country'].notna()].sample(10)[['title', 'predicted_country']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4sm411Y5MCni",
        "outputId": "ac6b6f4f-8444-4144-8ccf-f43b06983957"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GeoText + Demonyms: Found 5888/92444 entries\n",
            "                                                   title predicted_country\n",
            "70306  Cheese exposed to hip-hop tastes better, finds...       Switzerland\n",
            "63749  Touch this fence and say hello to the Israeli ...            Israel\n",
            "41688                    Nothing like a Vulcan Mind Meld            Vulcan\n",
            "69162  U.S. spacecraft to take slingshot dive inside ...     United States\n",
            "45014  Police: Warren teen caught having sex with wie...            Vienna\n",
            "40297  I decided to take this pic of the caribbean Mo...         Caribbean\n",
            "41551  If it quacks like a duck: boisterous poultry l...            France\n",
            "38291  German soldier celebrates after successfully g...           Germany\n",
            "52327  My Chinese manufactured Led Zeppelin LP with a...             China\n",
            "11650  In 1920’s Germany, a man single-handedly lower...           Germany\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Without Dymonyms"
      ],
      "metadata": {
        "id": "9hcjbF2sMHKK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from geotext import GeoText\n",
        "\n",
        "def get_country_geotext(text):\n",
        "    places = GeoText(str(text))\n",
        "    return places.countries[0] if places.countries else None\n",
        "\n",
        "df_copy['predicted_country'] = df_copy['title'].apply(get_country_geotext)\n",
        "found = df_copy['predicted_country'].notna().sum()\n",
        "print(f\"GeoText Only: Found {found}/{len(df_copy)} entries\")\n",
        "df_copy.to_csv('all_validate_geotext_nodemonym.csv', index=False)\n",
        "print(df_copy[df_copy['predicted_country'].notna()].sample(10)[['title', 'predicted_country']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-f4CZSjMJun",
        "outputId": "51ebff83-8579-45cc-9604-c69c57bab39f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GeoText Only: Found 3397/92444 entries\n",
            "                                                   title predicted_country\n",
            "11269  'Yolocaust' artist provokes debate over commem...           Germany\n",
            "85134       River basins of the contiguous United States     United States\n",
            "26359  This lake in India is straight out of a horror...             India\n",
            "74570  Ronald McDonald resting after an attack on Col...              Iraq\n",
            "84052               Missles over Syria, Colorized (2018)             Syria\n",
            "79853  Anesthesia Provision in the United States - It...     United States\n",
            "91767  China and Russia are teaming up to ban illegal...             China\n",
            "31883  A man in Australia has scooped a $1m (£536,000...         Australia\n",
            "72505  U.S., Japan in talks to prevent China acquirin...             Japan\n",
            "44815  Vatican launches $110 'click to pray' wearable...           Vatican\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Geograpy3"
      ],
      "metadata": {
        "id": "omlziR56MRha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/JoshData/geograpy3.git\n",
        "\n",
        "!pip install lxml[html_clean]\n",
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzzPfu8-MauR",
        "outputId": "986aa454-6b8b-4634-88b2-d52627c3f698"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/JoshData/geograpy3.git\n",
            "  Cloning https://github.com/JoshData/geograpy3.git to /tmp/pip-req-build-dyfyv_lp\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/JoshData/geograpy3.git /tmp/pip-req-build-dyfyv_lp\n",
            "  fatal: could not read Username for 'https://github.com': No such device or address\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mgit clone --\u001b[0m\u001b[32mfilter\u001b[0m\u001b[32m=\u001b[0m\u001b[32mblob\u001b[0m\u001b[32m:none --quiet \u001b[0m\u001b[4;32mhttps://github.com/JoshData/geograpy3.git\u001b[0m\u001b[32m \u001b[0m\u001b[32m/tmp/\u001b[0m\u001b[32mpip-req-build-dyfyv_lp\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m128\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m \u001b[32mgit clone --\u001b[0m\u001b[32mfilter\u001b[0m\u001b[32m=\u001b[0m\u001b[32mblob\u001b[0m\u001b[32m:none --quiet \u001b[0m\u001b[4;32mhttps://github.com/JoshData/geograpy3.git\u001b[0m\u001b[32m \u001b[0m\u001b[32m/tmp/\u001b[0m\u001b[32mpip-req-build-dyfyv_lp\u001b[0m did not run successfully.\n",
            "\u001b[31m│\u001b[0m exit code: \u001b[1;36m128\u001b[0m\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "Requirement already satisfied: lxml[html_clean] in /usr/local/lib/python3.11/dist-packages (5.4.0)\n",
            "Collecting lxml_html_clean (from lxml[html_clean])\n",
            "  Downloading lxml_html_clean-0.4.2-py3-none-any.whl.metadata (2.4 kB)\n",
            "Downloading lxml_html_clean-0.4.2-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: lxml_html_clean\n",
            "Successfully installed lxml_html_clean-0.4.2\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "\n",
        "import geograpy as geograpy\n",
        "\n",
        "text = \"The prime minister of Canada met with officials from the United States and the United Kingdom.\"\n",
        "places = geograpy.get_place_context(text=text)\n",
        "\n",
        "print(\"Countries:\", places.countries)\n",
        "print(\"Regions:\", places.regions)\n",
        "print(\"Cities:\", places.cities)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "id": "8pIn1Hl9O7R0",
        "outputId": "1ca0f835-dd04-452c-f5ac-0d6cf9f8f539"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'geograpy'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-51e38e4f8de3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'words'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgeograpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgeograpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"The prime minister of Canada met with officials from the United States and the United Kingdom.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'geograpy'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## With Dymonyms"
      ],
      "metadata": {
        "id": "0kgKyTtsMTZt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import geograpy\n",
        "\n",
        "# Load datasets\n",
        "df = pd.read_csv('all_validate.csv')\n",
        "df_copy = df.copy()\n",
        "demonyms_df = pd.read_csv('demonyms.csv', header=None)\n",
        "demonym_map = dict(zip(demonyms_df[0].str.lower(), demonyms_df[1]))\n",
        "\n",
        "# Geograpy + Demonyms\n",
        "def get_country_geograpy_with_demonyms(text):\n",
        "    text = str(text).lower()\n",
        "    places = geograpy.get_place_context(text=text)\n",
        "    countries = places.countries\n",
        "    if countries:\n",
        "        return countries[0]\n",
        "    for word in text.split():\n",
        "        if word in demonym_map:\n",
        "            return demonym_map[word]\n",
        "    return None\n",
        "\n",
        "df_copy['predicted_country'] = df_copy['title'].apply(get_country_geograpy_with_demonyms)\n",
        "found = df_copy['predicted_country'].notna().sum()\n",
        "print(f\"Geograpy + Demonyms: Found {found}/{len(df_copy)} entries\")\n",
        "df_copy.to_csv('all_validate_geograpy.csv', index=False)\n",
        "print(df_copy[df_copy['predicted_country'].notna()].sample(10)[['title', 'predicted_country']])"
      ],
      "metadata": {
        "id": "pTUd80INMV1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. SpacyEr"
      ],
      "metadata": {
        "id": "a7OL16QXSUY_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRiz9tLMSmHe",
        "outputId": "e519426e-9625-4466-cd61-3a66d7dad9c0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.6)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.11.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.13.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.4.26)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## With Demonyms"
      ],
      "metadata": {
        "id": "GFuU2QwqSZg1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def get_country_spacy_with_demonyms(text):\n",
        "    text = str(text)\n",
        "    doc = nlp(text)\n",
        "    for ent in doc.ents:\n",
        "        if ent.label_ == \"GPE\":\n",
        "            return ent.text\n",
        "    for word in text.lower().split():\n",
        "        if word in demonym_map:\n",
        "            return demonym_map[word]\n",
        "    return None\n",
        "\n",
        "df_copy['predicted_country'] = df_copy['title'].apply(get_country_spacy_with_demonyms)\n",
        "found = df_copy['predicted_country'].notna().sum()\n",
        "print(f\"spaCy + Demonyms: Found {found}/{len(df_copy)} entries\")\n",
        "df_copy.to_csv('all_validate_spacy.csv', index=False)\n",
        "print(df_copy[df_copy['predicted_country'].notna()].sample(10)[['title', 'predicted_country']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtQ3ejAnSYVE",
        "outputId": "ba62e518-0e69-4924-dd8a-ebe1627c1a2e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spaCy + Demonyms: Found 14639/92444 entries\n",
            "                                                   title predicted_country\n",
            "5861   Washing machine can’t believe how much deterge...               n’t\n",
            "14224  Traditional Indian parents throw their son a h...             India\n",
            "77377                             Take us to your leader     United States\n",
            "70786            \"Massacre in Korea\" Pablo Picasso, 1951             Korea\n",
            "87747  Farrakhan: Giuliani Grew Up a 'Privileged Crac...           Florida\n",
            "68530    The Tostitos logo has two people dipping a chip          Tostitos\n",
            "60568  Un cavalier de LBD de Gaza sur la route des Gaza.                la\n",
            "2404     The USA announces our freedom from England 1776           England\n",
            "85783  UK to back total ban on pesticides harmful to ...                UK\n",
            "79399                                 The King of Queens            Queens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Without Demonyms"
      ],
      "metadata": {
        "id": "Qn9qz232ScJj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def get_country_spacy(text):\n",
        "    doc = nlp(str(text))\n",
        "    for ent in doc.ents:\n",
        "        if ent.label_ == \"GPE\":\n",
        "            return ent.text\n",
        "    return None\n",
        "\n",
        "df_copy['predicted_country'] = df_copy['title'].apply(get_country_spacy)\n",
        "found = df_copy['predicted_country'].notna().sum()\n",
        "print(f\"spaCy Only: Found {found}/{len(df_copy)} entries\")\n",
        "df_copy.to_csv('all_validate_spacy_nodemonym.csv', index=False)\n",
        "print(df_copy[df_copy['predicted_country'].notna()].sample(10)[['title', 'predicted_country']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_1fGE3cSeJk",
        "outputId": "d763124b-bb47-4e42-a115-03d6d7152a0d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spaCy Only: Found 10666/92444 entries\n",
            "                                                   title predicted_country\n",
            "47313  PsBattle: Anti-austerity protester in Athens, ...            Athens\n",
            "59214      TIFU by soaking myself in lingerie on Dropbox           Dropbox\n",
            "7574   All 25 wanted individuals on Hawaii Island las...     Hawaii Island\n",
            "77451  Adolf Hitler, leader of Nazi Germany, marches ...           Germany\n",
            "39404  England forget to tick box to allow cyclist to...           England\n",
            "38416               Best vending mashine ever in germany           germany\n",
            "63763  David Ben Gurion, The 1st Prime Minister of Is...            Israel\n",
            "88280  200 (1975) -- a psychedelic animated short by ...               USA\n",
            "78836  Egypt: Man's 'drugs test trick' foiled by preg...             Egypt\n",
            "38973  Tumblrina tries to embarrass Mike Pence at the...            Canada\n"
          ]
        }
      ]
    }
  ]
}